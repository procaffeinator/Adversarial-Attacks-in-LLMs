{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Make sure you have requested access for LLama on huggingface and meta. Once granted you can proceed further**\n",
        "\n",
        "# Cloning the repo"
      ],
      "metadata": {
        "id": "XBXS18voF89J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afQsrtUQ5qoi",
        "outputId": "029c8bbf-5da3-4622-c202-be53903447b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Jailbreak_LLM'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 60 (delta 25), reused 21 (delta 7), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (60/60), 300.90 KiB | 3.01 MiB/s, done.\n",
            "Resolving deltas: 100% (25/25), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/aviralagrawal/Jailbreak_LLM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd Jailbreak_LLM/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUeTdFSg-p9F",
        "outputId": "ffc09463-d31a-4489-9c2c-56faa58be2fe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Jailbreak_LLM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnMgp9TtUWCK",
        "outputId": "d9562bad-c17d-47e8-82f9-78c73c6cd8ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get the huggingface keys from your account\n",
        "https://huggingface.co/settings/tokens\n",
        "\n",
        "Generate a new token for the project if you haven't"
      ],
      "metadata": {
        "id": "_q3jqekBu0V0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "access_token_write = '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'\n",
        "login(token = access_token_write)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSqt36c4F3ZM",
        "outputId": "12f1a388-94e1-4ef8-a5c3-f2f91aabd467"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pklZJVKcaRcb",
        "outputId": "19c836ad-11ad-4ea4-db6e-26a9141cae20"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running the attack"
      ],
      "metadata": {
        "id": "csFjWrvVu85z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before running the attack please make sure you edit the dataset file. You can change either existingdataset.txt or newdataset.txt for your prompts. Our newly created prompts are in the newdataset.txt file. You can switch between datasets in the attack or evaluate script using argument use_existingdataset (for using existing dataset) or not using it.\n"
      ],
      "metadata": {
        "id": "-k8KzW-eChQa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Default configuration"
      ],
      "metadata": {
        "id": "WDPxRvSyvARx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !python attack.py \\\n",
        "#     --model Llama-2-7b-chat-hf \\\n",
        "#     --use_existingdataset \\\n",
        "#     --use_default \\"
      ],
      "metadata": {
        "id": "Murwq-Ed5xU7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Greedy configuration"
      ],
      "metadata": {
        "id": "xmqBiZ0IDWT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python attack.py \\\n",
        "    --model Llama-2-7b-hf \\\n",
        "    --use_existingdataset \\\n",
        "    --use_greedy \\\n",
        "    --n_sample 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1CvPj0kyHXv",
        "outputId": "4b0f280e-d49c-47ed-b147-f57f1245bd27"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "Loading checkpoint shards: 100% 2/2 [01:07<00:00, 33.82s/it]\n",
            "INFO:root:Model size: 13.543948288\n",
            "INFO:root:Model name: Llama-2-7b-hf_existingdataset\n",
            "INFO:root:Running greedy\n",
            "100% 10/10 [01:03<00:00,  6.34s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Using exhaustive iteration"
      ],
      "metadata": {
        "id": "Xd66P57KDY-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python attack.py \\\n",
        "    --model Llama-2-7b-hf \\\n",
        "    --use_existingdataset \\\n",
        "    --tune_temp \\\n",
        "    --tune_topp \\\n",
        "    --tune_topk \\\n",
        "    --n_sample 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioK7gjmHC1SL",
        "outputId": "7b04a60b-b212-46dc-b637-cb925735be32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "Loading checkpoint shards: 100% 2/2 [00:54<00:00, 27.30s/it]\n",
            "INFO:root:Model size: 13.543948288\n",
            "INFO:root:Model name: Llama-2-7b-chat-hf_existingdataset\n",
            "INFO:root:Running temp = 0.05\n",
            "100% 10/10 [01:02<00:00,  6.30s/it]\n",
            "INFO:root:Running temp = 0.1\n",
            "100% 10/10 [01:00<00:00,  6.04s/it]\n",
            "INFO:root:Running temp = 0.15\n",
            "100% 10/10 [01:00<00:00,  6.04s/it]\n",
            "INFO:root:Running temp = 0.2\n",
            "100% 10/10 [01:00<00:00,  6.04s/it]\n",
            "INFO:root:Running temp = 0.25\n",
            "100% 10/10 [00:54<00:00,  5.47s/it]\n",
            "INFO:root:Running temp = 0.3\n",
            "100% 10/10 [01:00<00:00,  6.03s/it]\n",
            "INFO:root:Running temp = 0.35\n",
            "100% 10/10 [00:54<00:00,  5.47s/it]\n",
            "INFO:root:Running temp = 0.4\n",
            "100% 10/10 [01:00<00:00,  6.03s/it]\n",
            "INFO:root:Running temp = 0.45\n",
            "100% 10/10 [01:00<00:00,  6.03s/it]\n",
            "INFO:root:Running temp = 0.5\n",
            "100% 10/10 [00:54<00:00,  5.46s/it]\n",
            "INFO:root:Running temp = 0.55\n",
            "100% 10/10 [01:00<00:00,  6.03s/it]\n",
            "INFO:root:Running temp = 0.6\n",
            "100% 10/10 [00:54<00:00,  5.46s/it]\n",
            "INFO:root:Running temp = 0.65\n",
            "100% 10/10 [01:00<00:00,  6.03s/it]\n",
            "INFO:root:Running temp = 0.7\n",
            "100% 10/10 [01:00<00:00,  6.03s/it]\n",
            "INFO:root:Running temp = 0.75\n",
            "100% 10/10 [00:54<00:00,  5.47s/it]\n",
            "INFO:root:Running temp = 0.8\n",
            "100% 10/10 [01:00<00:00,  6.03s/it]\n",
            "INFO:root:Running temp = 0.85\n",
            "100% 10/10 [01:00<00:00,  6.03s/it]\n",
            "INFO:root:Running temp = 0.9\n",
            "100% 10/10 [01:00<00:00,  6.04s/it]\n",
            "INFO:root:Running temp = 0.95\n",
            "100% 10/10 [01:00<00:00,  6.05s/it]\n",
            "INFO:root:Running temp = 1.0\n",
            "100% 10/10 [00:55<00:00,  5.54s/it]\n",
            "INFO:root:Running topp = 0.0\n",
            "100% 10/10 [01:00<00:00,  6.04s/it]\n",
            "INFO:root:Running topp = 0.05\n",
            "100% 10/10 [01:00<00:00,  6.04s/it]\n",
            "INFO:root:Running topp = 0.1\n",
            "100% 10/10 [01:00<00:00,  6.04s/it]\n",
            "INFO:root:Running topp = 0.15\n",
            "100% 10/10 [01:00<00:00,  6.04s/it]\n",
            "INFO:root:Running topp = 0.2\n",
            "100% 10/10 [01:00<00:00,  6.03s/it]\n",
            "INFO:root:Running topp = 0.25\n",
            "100% 10/10 [01:00<00:00,  6.04s/it]\n",
            "INFO:root:Running topp = 0.3\n",
            "100% 10/10 [00:54<00:00,  5.48s/it]\n",
            "INFO:root:Running topp = 0.35\n",
            "100% 10/10 [00:54<00:00,  5.47s/it]\n",
            "INFO:root:Running topp = 0.4\n",
            "100% 10/10 [01:00<00:00,  6.03s/it]\n",
            "INFO:root:Running topp = 0.45\n",
            "100% 10/10 [01:00<00:00,  6.05s/it]\n",
            "INFO:root:Running topp = 0.5\n",
            "100% 10/10 [01:00<00:00,  6.04s/it]\n",
            "INFO:root:Running topp = 0.55\n",
            "100% 10/10 [01:00<00:00,  6.03s/it]\n",
            "INFO:root:Running topp = 0.6\n",
            "100% 10/10 [01:00<00:00,  6.03s/it]\n",
            "INFO:root:Running topp = 0.65\n",
            "100% 10/10 [01:00<00:00,  6.04s/it]\n",
            "INFO:root:Running topp = 0.7\n",
            "100% 10/10 [01:00<00:00,  6.03s/it]\n",
            "INFO:root:Running topp = 0.75\n",
            "100% 10/10 [01:00<00:00,  6.04s/it]\n",
            "INFO:root:Running topp = 0.8\n",
            "100% 10/10 [01:00<00:00,  6.03s/it]\n",
            "INFO:root:Running topp = 0.85\n",
            "100% 10/10 [01:00<00:00,  6.03s/it]\n",
            "INFO:root:Running topp = 0.9\n",
            "100% 10/10 [01:00<00:00,  6.03s/it]\n",
            "INFO:root:Running topp = 0.95\n",
            "100% 10/10 [01:00<00:00,  6.03s/it]\n",
            "INFO:root:Running topp = 1.0\n",
            "100% 10/10 [01:00<00:00,  6.01s/it]\n",
            "INFO:root:Running topk = 1\n",
            "100% 10/10 [01:00<00:00,  6.03s/it]\n",
            "INFO:root:Running topk = 2\n",
            "100% 10/10 [01:00<00:00,  6.03s/it]\n",
            "INFO:root:Running topk = 5\n",
            "100% 10/10 [01:00<00:00,  6.04s/it]\n",
            "INFO:root:Running topk = 10\n",
            "100% 10/10 [01:00<00:00,  6.05s/it]\n",
            "INFO:root:Running topk = 20\n",
            "100% 10/10 [01:00<00:00,  6.05s/it]\n",
            "INFO:root:Running topk = 50\n",
            "100% 10/10 [01:00<00:00,  6.04s/it]\n",
            "INFO:root:Running topk = 100\n",
            "100% 10/10 [01:00<00:00,  6.05s/it]\n",
            "INFO:root:Running topk = 200\n",
            "100% 10/10 [01:00<00:00,  6.05s/it]\n",
            "INFO:root:Running topk = 500\n",
            "100% 10/10 [01:00<00:00,  6.07s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of the attack!"
      ],
      "metadata": {
        "id": "-dSiZIoMutde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --folder \"https://drive.google.com/drive/folders/1G0bxoe7lNfpaEQKqBb3JW5M0db9GJ5BR\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-3EtNFofiGu",
        "outputId": "6e6b1fa4-a618-4289-d7ed-fd970fcb193a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder list\n",
            "Retrieving folder 1De1bdq1BOa7rFl13eG_-qHK0m-v_UvQ9 evaluator\n",
            "Processing file 1ISNjwa_QrloDfbTrxoHu_hCUbII0g90v config.json\n",
            "Processing file 1bCg6CPX9uxH6KeeIHDHtaATYIQTljDto pytorch_model.bin\n",
            "Retrieving folder 1saRrjn63eCSW8boc-4IfK8Q5NZYubijz scorer\n",
            "Processing file 1_ennUtYbxewxb8Y5vjI7d5Z5y9mooTIX config.json\n",
            "Processing file 10UmcuYU4H82g9nvYRBqTo_avnwnJyEOI pytorch_model.bin\n",
            "Retrieving folder list completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ISNjwa_QrloDfbTrxoHu_hCUbII0g90v\n",
            "To: /content/Jailbreak_LLM/checkpoints/evaluator/config.json\n",
            "100% 764/764 [00:00<00:00, 4.35MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1bCg6CPX9uxH6KeeIHDHtaATYIQTljDto\n",
            "To: /content/Jailbreak_LLM/checkpoints/evaluator/pytorch_model.bin\n",
            "100% 433M/433M [00:01<00:00, 255MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_ennUtYbxewxb8Y5vjI7d5Z5y9mooTIX\n",
            "To: /content/Jailbreak_LLM/checkpoints/scorer/config.json\n",
            "100% 764/764 [00:00<00:00, 3.75MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10UmcuYU4H82g9nvYRBqTo_avnwnJyEOI\n",
            "To: /content/Jailbreak_LLM/checkpoints/scorer/pytorch_model.bin\n",
            "100% 433M/433M [00:01<00:00, 266MB/s]\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate.py \\\n",
        "    --model \"Llama-2-7b-hf\"\\\n",
        "    --config 'greedy-only' \\\n",
        "    --use_existingdataset \\\n",
        "    --evaluator_path  'checkpoints/evaluator'\\\n",
        "    --scorer_path 'checkpoints/scorer'"
      ],
      "metadata": {
        "id": "j5YUB5WUgvpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27f5774d-5d20-4238-b5b8-c4cc606cd72c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-01 18:04:34.448059: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-01 18:04:34.448118: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-01 18:04:34.448149: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-01 18:04:35.585919: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Llama-2-7b-hf_existingdataset Llama-2-7b-hf_existingdataset\n",
            "==== Greedy decoding ====\n",
            "/content/Jailbreak_LLM/evaluate.py:108: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  res[res[\"prompt\"].str.contains(p)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BwgGY_9bpaOC"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}