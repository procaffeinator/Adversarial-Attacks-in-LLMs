{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "WDPxRvSyvARx",
        "9qJ7s0E_RxG8"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Make sure you have requested access for LLama on huggingface and meta. Once granted you can proceed further**\n",
        "\n",
        "# Cloning the repo"
      ],
      "metadata": {
        "id": "XBXS18voF89J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afQsrtUQ5qoi",
        "outputId": "82fed5e9-bd6f-4048-c663-8d45aa843b68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Jailbreak_LLM' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Princeton-SysML/Jailbreak_LLM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd Jailbreak_LLM/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUeTdFSg-p9F",
        "outputId": "4fbd9a17-2ca6-49d6-af55-0f080b770146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Jailbreak_LLM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get the huggingface keys from your account\n",
        "https://huggingface.co/settings/tokens\n",
        "\n",
        "Generate a new token for the project if you haven't"
      ],
      "metadata": {
        "id": "_q3jqekBu0V0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "access_token_write = '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'\n",
        "login(token = access_token_write)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSqt36c4F3ZM",
        "outputId": "444ec393-a1cd-4c26-b9a3-6ff21dcd3289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pklZJVKcaRcb",
        "outputId": "677a4e13-1793-46a1-c690-fa450eb3aaa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running the attack"
      ],
      "metadata": {
        "id": "csFjWrvVu85z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before running the attack please make sure you edit the file configs.py and replace the different models with correct huggingface links as follows:\n",
        "\n",
        "\"Llama-2-7b-chat-hf\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
        "\n",
        "\"Llama-2-13b-chat-hf\": \"meta-llama/Llama-2-13b-chat-hf\",\n",
        "\n",
        "\"Llama-2-7b-hf\": \"meta-llama/Llama-2-7b-hf\",\n",
        "\n",
        "\"Llama-2-13b-hf\": \"meta-llama/Llama-2-13b-hf\","
      ],
      "metadata": {
        "id": "-k8KzW-eChQa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Default configuration"
      ],
      "metadata": {
        "id": "WDPxRvSyvARx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !python attack.py \\\n",
        "#     --model Llama-2-7b-hf \\\n",
        "#     --use_default \\\n",
        "#     --use_system_prompt"
      ],
      "metadata": {
        "id": "Murwq-Ed5xU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Greedy configuration"
      ],
      "metadata": {
        "id": "xmqBiZ0IDWT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python attack.py \\\n",
        "    --model Llama-2-7b-chat-hf \\\n",
        "    --use_greedy \\\n",
        "    --n_sample 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1CvPj0kyHXv",
        "outputId": "56c0c05a-a513-4c57-a1b4-e3bcb624e5bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json: 100% 614/614 [00:00<00:00, 3.40MB/s]\n",
            "model.safetensors.index.json: 100% 26.8k/26.8k [00:00<00:00, 23.1MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/9.98G [00:00<01:42, 96.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 31.5M/9.98G [00:00<01:06, 150MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 62.9M/9.98G [00:00<00:52, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 94.4M/9.98G [00:00<00:43, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 126M/9.98G [00:00<00:39, 250MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 157M/9.98G [00:00<00:38, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 189M/9.98G [00:00<00:37, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 220M/9.98G [00:00<00:39, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 252M/9.98G [00:01<00:38, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 283M/9.98G [00:03<03:55, 41.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 304M/9.98G [00:04<05:30, 29.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 325M/9.98G [00:04<04:23, 36.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 346M/9.98G [00:05<03:40, 43.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 377M/9.98G [00:05<02:37, 61.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 409M/9.98G [00:05<01:56, 82.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 440M/9.98G [00:05<01:31, 104MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 461M/9.98G [00:05<01:22, 115MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 482M/9.98G [00:05<01:13, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 514M/9.98G [00:05<01:02, 151MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 535M/9.98G [00:05<00:59, 159MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 556M/9.98G [00:05<00:56, 167MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 577M/9.98G [00:06<00:54, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 608M/9.98G [00:06<00:49, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 640M/9.98G [00:06<00:44, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 671M/9.98G [00:06<00:48, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 692M/9.98G [00:06<00:48, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 713M/9.98G [00:06<00:48, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 734M/9.98G [00:06<00:48, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 755M/9.98G [00:06<00:48, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 776M/9.98G [00:09<06:00, 25.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 797M/9.98G [00:09<04:30, 34.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 818M/9.98G [00:09<03:37, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 839M/9.98G [00:10<02:46, 54.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 870M/9.98G [00:10<01:56, 78.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 902M/9.98G [00:10<01:27, 104MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 933M/9.98G [00:10<01:09, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 965M/9.98G [00:10<01:07, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 996M/9.98G [00:10<00:58, 154MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 1.03G/9.98G [00:10<00:51, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.06G/9.98G [00:11<00:47, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.09G/9.98G [00:11<00:44, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.12G/9.98G [00:11<00:43, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.15G/9.98G [00:11<00:41, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.18G/9.98G [00:11<00:40, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.22G/9.98G [00:11<00:38, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.25G/9.98G [00:11<00:38, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.28G/9.98G [00:11<00:37, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.31G/9.98G [00:12<00:37, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.34G/9.98G [00:12<00:38, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.37G/9.98G [00:12<00:35, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.41G/9.98G [00:12<00:36, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.44G/9.98G [00:12<00:34, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.47G/9.98G [00:12<00:33, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.50G/9.98G [00:12<00:32, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.53G/9.98G [00:13<00:33, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.56G/9.98G [00:13<00:32, 259MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.59G/9.98G [00:13<00:32, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.63G/9.98G [00:13<00:36, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.66G/9.98G [00:13<00:38, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.69G/9.98G [00:13<00:38, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.72G/9.98G [00:13<00:38, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.75G/9.98G [00:14<00:37, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.78G/9.98G [00:14<00:36, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.81G/9.98G [00:14<01:03, 128MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.84G/9.98G [00:14<01:01, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.86G/9.98G [00:14<01:06, 123MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.89G/9.98G [00:15<00:53, 151MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.92G/9.98G [00:15<00:46, 172MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.95G/9.98G [00:15<00:41, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.98G/9.98G [00:15<00:43, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.01G/9.98G [00:15<00:40, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.04G/9.98G [00:15<00:38, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.08G/9.98G [00:15<00:36, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.11G/9.98G [00:16<00:34, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.14G/9.98G [00:16<00:34, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.17G/9.98G [00:16<00:34, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.20G/9.98G [00:16<00:33, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.23G/9.98G [00:16<00:47, 161MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.26G/9.98G [00:16<00:41, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.30G/9.98G [00:17<00:36, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.33G/9.98G [00:17<00:34, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.36G/9.98G [00:17<00:33, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.39G/9.98G [00:17<00:33, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.42G/9.98G [00:19<03:02, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.44G/9.98G [00:19<02:31, 49.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.46G/9.98G [00:19<02:04, 60.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.50G/9.98G [00:19<01:31, 81.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.53G/9.98G [00:20<01:10, 106MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.56G/9.98G [00:20<00:59, 126MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.59G/9.98G [00:20<00:55, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.62G/9.98G [00:20<00:47, 155MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.65G/9.98G [00:20<00:44, 164MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.67G/9.98G [00:20<00:42, 171MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.71G/9.98G [00:20<00:39, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.74G/9.98G [00:21<00:39, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.77G/9.98G [00:21<00:39, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.80G/9.98G [00:21<00:35, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.83G/9.98G [00:21<00:34, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.86G/9.98G [00:21<00:32, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.89G/9.98G [00:21<00:32, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.93G/9.98G [00:22<00:32, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.96G/9.98G [00:22<00:33, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.99G/9.98G [00:22<00:32, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.02G/9.98G [00:22<00:31, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.05G/9.98G [00:24<02:43, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.07G/9.98G [00:24<02:20, 49.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.09G/9.98G [00:24<01:54, 60.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.12G/9.98G [00:25<01:23, 81.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.16G/9.98G [00:25<01:05, 104MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.18G/9.98G [00:25<00:59, 115MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.21G/9.98G [00:25<00:47, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.24G/9.98G [00:25<00:46, 146MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.27G/9.98G [00:25<00:40, 165MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.30G/9.98G [00:25<00:37, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.33G/9.98G [00:26<00:35, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.37G/9.98G [00:26<00:33, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.40G/9.98G [00:26<00:31, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.43G/9.98G [00:26<00:29, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.46G/9.98G [00:26<00:27, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.49G/9.98G [00:26<00:27, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.52G/9.98G [00:26<00:26, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.55G/9.98G [00:26<00:26, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.59G/9.98G [00:27<00:26, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.62G/9.98G [00:27<00:25, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.65G/9.98G [00:27<00:25, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.68G/9.98G [00:27<00:24, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.71G/9.98G [00:27<00:24, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.74G/9.98G [00:27<00:24, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.77G/9.98G [00:27<00:25, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.81G/9.98G [00:27<00:25, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.84G/9.98G [00:28<00:25, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.87G/9.98G [00:28<00:24, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.90G/9.98G [00:28<00:23, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.93G/9.98G [00:28<00:24, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 3.96G/9.98G [00:28<00:23, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.00G/9.98G [00:28<00:23, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.03G/9.98G [00:28<00:22, 262MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.06G/9.98G [00:28<00:23, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.09G/9.98G [00:29<00:24, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.12G/9.98G [00:29<00:25, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.15G/9.98G [00:29<00:25, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.18G/9.98G [00:29<00:24, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.22G/9.98G [00:30<00:52, 111MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.25G/9.98G [00:30<00:42, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.28G/9.98G [00:30<00:35, 159MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.31G/9.98G [00:30<00:31, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.34G/9.98G [00:30<00:27, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.37G/9.98G [00:30<00:26, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.40G/9.98G [00:30<00:25, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.44G/9.98G [00:30<00:25, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.47G/9.98G [00:31<00:25, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.50G/9.98G [00:31<00:25, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.53G/9.98G [00:31<00:25, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.56G/9.98G [00:31<00:24, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.59G/9.98G [00:31<00:24, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.62G/9.98G [00:31<00:24, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.66G/9.98G [00:31<00:23, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.69G/9.98G [00:32<00:22, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.72G/9.98G [00:32<00:22, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.75G/9.98G [00:32<00:21, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.78G/9.98G [00:32<00:22, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.81G/9.98G [00:32<00:21, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.84G/9.98G [00:32<00:22, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.88G/9.98G [00:32<00:22, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.91G/9.98G [00:33<00:21, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.94G/9.98G [00:33<00:22, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.97G/9.98G [00:33<00:23, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 5.00G/9.98G [00:33<00:23, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 5.03G/9.98G [00:34<01:08, 72.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.05G/9.98G [00:34<00:58, 84.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.08G/9.98G [00:34<00:50, 97.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.10G/9.98G [00:34<00:43, 112MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.13G/9.98G [00:35<00:35, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.16G/9.98G [00:35<00:29, 163MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.19G/9.98G [00:35<00:29, 161MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.21G/9.98G [00:35<00:29, 164MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.24G/9.98G [00:35<00:26, 179MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.26G/9.98G [00:35<00:27, 170MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.28G/9.98G [00:35<00:26, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.32G/9.98G [00:36<00:23, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.35G/9.98G [00:36<00:22, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.38G/9.98G [00:36<00:21, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.41G/9.98G [00:36<00:21, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.44G/9.98G [00:36<00:20, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.47G/9.98G [00:36<00:20, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.51G/9.98G [00:36<00:19, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.54G/9.98G [00:36<00:18, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.57G/9.98G [00:37<00:18, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.60G/9.98G [00:37<00:18, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.63G/9.98G [00:37<00:18, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.66G/9.98G [00:37<00:17, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.69G/9.98G [00:37<00:18, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.73G/9.98G [00:37<00:18, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.76G/9.98G [00:37<00:17, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.79G/9.98G [00:37<00:16, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.82G/9.98G [00:38<00:16, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.85G/9.98G [00:38<00:16, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.88G/9.98G [00:38<00:16, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.91G/9.98G [00:38<00:16, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.95G/9.98G [00:38<00:15, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.98G/9.98G [00:38<00:15, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 6.01G/9.98G [00:38<00:15, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.04G/9.98G [00:38<00:15, 261MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.07G/9.98G [00:39<00:15, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.10G/9.98G [00:39<00:14, 261MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.13G/9.98G [00:39<00:14, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.17G/9.98G [00:39<00:15, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.20G/9.98G [00:39<00:14, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.23G/9.98G [00:39<00:14, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.26G/9.98G [00:39<00:15, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.29G/9.98G [00:39<00:14, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.32G/9.98G [00:40<00:15, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.35G/9.98G [00:40<00:15, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.39G/9.98G [00:40<00:14, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.42G/9.98G [00:40<00:15, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.45G/9.98G [00:40<00:14, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.48G/9.98G [00:40<00:14, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.51G/9.98G [00:40<00:14, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.54G/9.98G [00:41<00:14, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.57G/9.98G [00:41<00:14, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.61G/9.98G [00:41<00:14, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.64G/9.98G [00:41<00:15, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.67G/9.98G [00:41<00:14, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.70G/9.98G [00:41<00:14, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.73G/9.98G [00:41<00:13, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.76G/9.98G [00:42<00:13, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.79G/9.98G [00:42<00:13, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.83G/9.98G [00:42<00:13, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.86G/9.98G [00:42<00:12, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.89G/9.98G [00:42<00:12, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.92G/9.98G [00:42<00:13, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.95G/9.98G [00:42<00:12, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.98G/9.98G [00:42<00:12, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 7.01G/9.98G [00:43<00:11, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.05G/9.98G [00:43<00:11, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.08G/9.98G [00:43<00:12, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.11G/9.98G [00:43<00:11, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.14G/9.98G [00:43<00:11, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.17G/9.98G [00:43<00:11, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.20G/9.98G [00:43<00:11, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.24G/9.98G [00:43<00:12, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.27G/9.98G [00:44<00:12, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.30G/9.98G [00:44<00:11, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.33G/9.98G [00:44<00:10, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.36G/9.98G [00:44<00:10, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.39G/9.98G [00:44<00:10, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.42G/9.98G [00:44<00:10, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.46G/9.98G [00:44<00:09, 266MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.49G/9.98G [00:44<00:09, 259MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.52G/9.98G [00:45<00:10, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.55G/9.98G [00:45<00:10, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.58G/9.98G [00:45<00:13, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.60G/9.98G [00:45<00:13, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.63G/9.98G [00:45<00:11, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.67G/9.98G [00:45<00:10, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.70G/9.98G [00:46<00:10, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.73G/9.98G [00:46<00:10, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.76G/9.98G [00:46<00:10, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.79G/9.98G [00:46<00:10, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.81G/9.98G [00:46<00:10, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.83G/9.98G [00:46<00:10, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.86G/9.98G [00:46<00:10, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.90G/9.98G [00:47<00:10, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.92G/9.98G [00:47<00:10, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.94G/9.98G [00:47<00:10, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.97G/9.98G [00:47<00:09, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 8.00G/9.98G [00:47<00:09, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 8.02G/9.98G [00:47<00:14, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.04G/9.98G [00:47<00:13, 147MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.06G/9.98G [00:48<00:12, 156MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.08G/9.98G [00:48<00:11, 160MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.11G/9.98G [00:49<00:44, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.14G/9.98G [00:49<00:30, 61.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.17G/9.98G [00:49<00:22, 81.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.19G/9.98G [00:50<00:19, 93.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.21G/9.98G [00:50<00:16, 108MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.23G/9.98G [00:50<00:14, 119MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.25G/9.98G [00:50<00:12, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.28G/9.98G [00:50<00:10, 161MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.30G/9.98G [00:50<00:10, 159MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.34G/9.98G [00:53<00:55, 29.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.36G/9.98G [00:54<01:09, 23.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.39G/9.98G [00:54<00:46, 34.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.41G/9.98G [00:54<00:36, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.43G/9.98G [00:55<00:29, 52.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.45G/9.98G [00:55<00:23, 64.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.47G/9.98G [00:55<00:18, 80.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.50G/9.98G [00:55<00:13, 106MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.52G/9.98G [00:55<00:12, 118MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.56G/9.98G [00:55<00:10, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.58G/9.98G [00:55<00:09, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.61G/9.98G [00:55<00:08, 163MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.64G/9.98G [00:56<00:07, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.67G/9.98G [00:56<00:06, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.70G/9.98G [00:56<00:05, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.73G/9.98G [00:56<00:05, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.77G/9.98G [00:56<00:05, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.80G/9.98G [00:56<00:04, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.83G/9.98G [00:56<00:04, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.86G/9.98G [00:56<00:04, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.89G/9.98G [00:57<00:04, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.92G/9.98G [00:57<00:04, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.95G/9.98G [00:57<00:04, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.99G/9.98G [00:57<00:04, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 9.02G/9.98G [00:57<00:03, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.05G/9.98G [00:57<00:03, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.08G/9.98G [00:57<00:03, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.11G/9.98G [00:57<00:03, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.14G/9.98G [00:58<00:03, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.18G/9.98G [00:58<00:03, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.21G/9.98G [00:58<00:03, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.24G/9.98G [00:58<00:02, 262MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.27G/9.98G [00:58<00:02, 267MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.30G/9.98G [00:58<00:02, 271MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.33G/9.98G [00:58<00:02, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.36G/9.98G [00:58<00:02, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.40G/9.98G [00:59<00:02, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.43G/9.98G [00:59<00:02, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.46G/9.98G [00:59<00:02, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.49G/9.98G [00:59<00:02, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.52G/9.98G [00:59<00:02, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.55G/9.98G [00:59<00:01, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.58G/9.98G [01:00<00:01, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.62G/9.98G [01:00<00:01, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.65G/9.98G [01:00<00:01, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.68G/9.98G [01:00<00:01, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.71G/9.98G [01:00<00:01, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.74G/9.98G [01:00<00:01, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.77G/9.98G [01:00<00:00, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.80G/9.98G [01:01<00:00, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.83G/9.98G [01:01<00:00, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.85G/9.98G [01:01<00:00, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.87G/9.98G [01:01<00:00, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.89G/9.98G [01:01<00:00, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.91G/9.98G [01:01<00:00, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.94G/9.98G [01:01<00:00, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.98G/9.98G [01:01<00:00, 161MB/s]\n",
            "Downloading shards:  50% 1/2 [01:02<01:02, 62.08s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 31.5M/3.50G [00:00<00:14, 237MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 62.9M/3.50G [00:00<00:15, 225MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 94.4M/3.50G [00:00<00:16, 208MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 115M/3.50G [00:00<00:16, 201MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 147M/3.50G [00:00<00:16, 203MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 168M/3.50G [00:02<01:16, 43.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 189M/3.50G [00:02<01:16, 43.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 220M/3.50G [00:02<00:52, 62.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 241M/3.50G [00:02<00:44, 73.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 262M/3.50G [00:03<00:38, 85.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 283M/3.50G [00:03<00:32, 99.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 304M/3.50G [00:03<00:27, 115MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 336M/3.50G [00:03<00:21, 144MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 357M/3.50G [00:03<00:20, 157MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 377M/3.50G [00:03<00:18, 166MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 409M/3.50G [00:03<00:16, 183MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 440M/3.50G [00:03<00:15, 198MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 472M/3.50G [00:04<00:14, 210MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 503M/3.50G [00:04<00:13, 217MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 535M/3.50G [00:04<00:13, 222MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 566M/3.50G [00:04<00:12, 228MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 598M/3.50G [00:04<00:12, 233MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 629M/3.50G [00:04<00:12, 233MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 661M/3.50G [00:04<00:11, 239MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20% 692M/3.50G [00:05<00:11, 239MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 724M/3.50G [00:05<00:11, 234MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 755M/3.50G [00:05<00:11, 241MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 786M/3.50G [00:05<00:11, 236MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  23% 818M/3.50G [00:05<00:11, 241MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 849M/3.50G [00:05<00:10, 248MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 881M/3.50G [00:05<00:15, 167MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26% 912M/3.50G [00:06<00:14, 184MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 944M/3.50G [00:06<00:12, 205MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 975M/3.50G [00:06<00:11, 217MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 1.01G/3.50G [00:06<00:10, 234MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 1.04G/3.50G [00:06<00:11, 222MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 1.07G/3.50G [00:06<00:10, 224MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 1.10G/3.50G [00:06<00:10, 227MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 1.13G/3.50G [00:07<00:10, 229MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 1.16G/3.50G [00:07<00:10, 228MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 1.20G/3.50G [00:07<00:10, 225MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35% 1.23G/3.50G [00:07<00:10, 225MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 1.26G/3.50G [00:07<00:10, 207MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 1.29G/3.50G [00:07<00:10, 217MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 1.32G/3.50G [00:07<00:09, 225MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 1.35G/3.50G [00:08<00:10, 213MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 1.38G/3.50G [00:08<00:09, 223MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 1.42G/3.50G [00:08<00:08, 240MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 1.45G/3.50G [00:08<00:08, 247MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 1.48G/3.50G [00:08<00:08, 250MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 1.51G/3.50G [00:08<00:07, 250MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 1.54G/3.50G [00:08<00:07, 245MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 1.57G/3.50G [00:08<00:07, 241MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 1.60G/3.50G [00:09<00:08, 236MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 1.64G/3.50G [00:09<00:08, 232MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 1.67G/3.50G [00:09<00:08, 227MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.70G/3.50G [00:09<00:07, 228MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.73G/3.50G [00:09<00:07, 231MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 1.76G/3.50G [00:09<00:07, 231MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 1.79G/3.50G [00:09<00:07, 234MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 1.82G/3.50G [00:10<00:07, 238MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 1.86G/3.50G [00:10<00:06, 249MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 1.89G/3.50G [00:10<00:06, 249MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 1.92G/3.50G [00:10<00:06, 242MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  56% 1.95G/3.50G [00:10<00:06, 250MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 1.98G/3.50G [00:10<00:06, 247MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 2.01G/3.50G [00:10<00:05, 249MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 2.04G/3.50G [00:10<00:05, 249MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 2.08G/3.50G [00:11<00:05, 247MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 2.11G/3.50G [00:11<00:06, 230MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 2.14G/3.50G [00:11<00:05, 235MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 2.17G/3.50G [00:11<00:06, 221MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 2.20G/3.50G [00:11<00:05, 221MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 2.23G/3.50G [00:11<00:05, 229MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 2.26G/3.50G [00:11<00:05, 218MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 2.30G/3.50G [00:12<00:06, 200MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 2.32G/3.50G [00:12<00:05, 199MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 2.34G/3.50G [00:12<00:05, 199MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 2.37G/3.50G [00:12<00:08, 132MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 2.39G/3.50G [00:12<00:07, 143MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 2.41G/3.50G [00:12<00:07, 154MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 2.43G/3.50G [00:13<00:06, 154MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 2.46G/3.50G [00:13<00:05, 178MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 2.50G/3.50G [00:13<00:05, 194MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 2.53G/3.50G [00:13<00:04, 203MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 2.56G/3.50G [00:13<00:04, 213MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 2.59G/3.50G [00:13<00:04, 219MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 2.62G/3.50G [00:13<00:04, 202MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 2.64G/3.50G [00:14<00:04, 187MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 2.66G/3.50G [00:14<00:04, 187MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 2.68G/3.50G [00:14<00:04, 188MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 2.72G/3.50G [00:14<00:04, 193MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 2.74G/3.50G [00:14<00:04, 188MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79% 2.76G/3.50G [00:14<00:04, 179MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79% 2.78G/3.50G [00:14<00:03, 186MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 2.81G/3.50G [00:14<00:03, 190MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 2.83G/3.50G [00:15<00:03, 192MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 2.85G/3.50G [00:15<00:03, 193MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 2.88G/3.50G [00:15<00:03, 200MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 2.90G/3.50G [00:16<00:10, 54.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 2.93G/3.50G [00:17<00:16, 33.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 2.96G/3.50G [00:17<00:10, 49.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 2.98G/3.50G [00:17<00:08, 60.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 3.00G/3.50G [00:18<00:06, 73.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 3.02G/3.50G [00:18<00:05, 87.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 3.04G/3.50G [00:18<00:04, 103MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 3.06G/3.50G [00:18<00:03, 120MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 3.09G/3.50G [00:18<00:02, 143MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  89% 3.11G/3.50G [00:18<00:02, 153MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 3.14G/3.50G [00:18<00:03, 113MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 3.17G/3.50G [00:19<00:02, 141MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 3.20G/3.50G [00:19<00:01, 164MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 3.23G/3.50G [00:19<00:01, 181MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 3.26G/3.50G [00:19<00:01, 194MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 3.29G/3.50G [00:19<00:01, 202MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 3.32G/3.50G [00:19<00:00, 217MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 3.36G/3.50G [00:19<00:00, 221MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 3.39G/3.50G [00:20<00:00, 226MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 3.42G/3.50G [00:20<00:00, 228MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  99% 3.45G/3.50G [00:20<00:00, 232MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 3.50G/3.50G [00:20<00:00, 170MB/s]\n",
            "Downloading shards: 100% 2/2 [01:22<00:00, 41.36s/it]\n",
            "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "Loading checkpoint shards: 100% 2/2 [01:02<00:00, 31.15s/it]\n",
            "generation_config.json: 100% 188/188 [00:00<00:00, 963kB/s]\n",
            "tokenizer_config.json: 100% 1.62k/1.62k [00:00<00:00, 7.88MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 315MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 26.5MB/s]\n",
            "special_tokens_map.json: 100% 414/414 [00:00<00:00, 2.50MB/s]\n",
            "INFO:root:Model size: 13.543948288\n",
            "INFO:root:Model name: Llama-2-7b-chat-hf\n",
            "INFO:root:Running greedy\n",
            "100% 10/10 [00:59<00:00,  5.99s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Top-K Sampling"
      ],
      "metadata": {
        "id": "9qJ7s0E_RxG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !python attack.py \\\n",
        "#     --model Llama-2-7b-hf \\\n",
        "#     --tune_topk \\\n",
        "#     --n_sample 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBjQ7TizRwVg",
        "outputId": "d1286b41-373f-4f67-d52e-9bc5370ad875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "Loading checkpoint shards: 100% 2/2 [00:57<00:00, 28.58s/it]\n",
            "INFO:root:Model size: 13.543948288\n",
            "INFO:root:Model name: Llama-2-7b-hf\n",
            "INFO:root:Running topk = 1\n",
            "100% 2/2 [00:14<00:00,  7.39s/it]\n",
            "INFO:root:Running topk = 2\n",
            "100% 2/2 [00:11<00:00,  5.98s/it]\n",
            "INFO:root:Running topk = 5\n",
            "100% 2/2 [00:12<00:00,  6.01s/it]\n",
            "INFO:root:Running topk = 10\n",
            "100% 2/2 [00:12<00:00,  6.04s/it]\n",
            "INFO:root:Running topk = 20\n",
            "100% 2/2 [00:12<00:00,  6.08s/it]\n",
            "INFO:root:Running topk = 50\n",
            "100% 2/2 [00:12<00:00,  6.18s/it]\n",
            "INFO:root:Running topk = 100\n",
            "100% 2/2 [00:12<00:00,  6.27s/it]\n",
            "INFO:root:Running topk = 200\n",
            " 50% 1/2 [00:07<00:07,  7.45s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Jailbreak_LLM/attack.py\", line 335, in <module>\n",
            "    main()\n",
            "  File \"/content/Jailbreak_LLM/attack.py\", line 327, in main\n",
            "    continue\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Using exhaustive iteration"
      ],
      "metadata": {
        "id": "Xd66P57KDY-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## exploited\n",
        "!python attack.py \\\n",
        "    --model Llama-2-7b-chat-hf \\\n",
        "    --tune_temp \\\n",
        "    --tune_topp \\\n",
        "    --tune_topk \\\n",
        "    --n_sample 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioK7gjmHC1SL",
        "outputId": "487295d3-1c9e-4333-f4d8-12424f060948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "Loading checkpoint shards: 100% 2/2 [01:04<00:00, 32.03s/it]\n",
            "INFO:root:Model size: 13.543948288\n",
            "INFO:root:Model name: Llama-2-7b-chat-hf\n",
            "INFO:root:Running temp = 0.05\n",
            "100% 10/10 [01:01<00:00,  6.12s/it]\n",
            "INFO:root:Running temp = 0.1\n",
            "100% 10/10 [00:59<00:00,  5.97s/it]\n",
            "INFO:root:Running temp = 0.15\n",
            "100% 10/10 [01:00<00:00,  6.00s/it]\n",
            "INFO:root:Running temp = 0.2\n",
            "100% 10/10 [01:00<00:00,  6.03s/it]\n",
            "INFO:root:Running temp = 0.25\n",
            "100% 10/10 [01:00<00:00,  6.05s/it]\n",
            "INFO:root:Running temp = 0.3\n",
            "100% 10/10 [01:00<00:00,  6.06s/it]\n",
            "INFO:root:Running temp = 0.35\n",
            "100% 10/10 [01:00<00:00,  6.07s/it]\n",
            "INFO:root:Running temp = 0.4\n",
            "100% 10/10 [01:00<00:00,  6.06s/it]\n",
            "INFO:root:Running temp = 0.45\n",
            "100% 10/10 [01:00<00:00,  6.06s/it]\n",
            "INFO:root:Running temp = 0.5\n",
            "100% 10/10 [01:00<00:00,  6.06s/it]\n",
            "INFO:root:Running temp = 0.55\n",
            "100% 10/10 [01:00<00:00,  6.07s/it]\n",
            "INFO:root:Running temp = 0.6\n",
            "100% 10/10 [01:00<00:00,  6.06s/it]\n",
            "INFO:root:Running temp = 0.65\n",
            "100% 10/10 [01:00<00:00,  6.07s/it]\n",
            "INFO:root:Running temp = 0.7\n",
            "100% 10/10 [00:55<00:00,  5.51s/it]\n",
            "INFO:root:Running temp = 0.75\n",
            "100% 10/10 [01:00<00:00,  6.07s/it]\n",
            "INFO:root:Running temp = 0.8\n",
            "100% 10/10 [01:00<00:00,  6.07s/it]\n",
            "INFO:root:Running temp = 0.85\n",
            "100% 10/10 [01:00<00:00,  6.06s/it]\n",
            "INFO:root:Running temp = 0.9\n",
            "100% 10/10 [01:00<00:00,  6.06s/it]\n",
            "INFO:root:Running temp = 0.95\n",
            "100% 10/10 [00:56<00:00,  5.62s/it]\n",
            "INFO:root:Running temp = 1.0\n",
            "100% 10/10 [01:00<00:00,  6.06s/it]\n",
            "INFO:root:Running topp = 0.0\n",
            "100% 10/10 [01:00<00:00,  6.08s/it]\n",
            "INFO:root:Running topp = 0.05\n",
            "100% 10/10 [01:00<00:00,  6.07s/it]\n",
            "INFO:root:Running topp = 0.1\n",
            "100% 10/10 [01:00<00:00,  6.07s/it]\n",
            "INFO:root:Running topp = 0.15\n",
            "100% 10/10 [01:00<00:00,  6.06s/it]\n",
            "INFO:root:Running topp = 0.2\n",
            "100% 10/10 [01:00<00:00,  6.07s/it]\n",
            "INFO:root:Running topp = 0.25\n",
            "100% 10/10 [01:00<00:00,  6.06s/it]\n",
            "INFO:root:Running topp = 0.3\n",
            "100% 10/10 [01:00<00:00,  6.07s/it]\n",
            "INFO:root:Running topp = 0.35\n",
            "100% 10/10 [01:00<00:00,  6.07s/it]\n",
            "INFO:root:Running topp = 0.4\n",
            "100% 10/10 [01:00<00:00,  6.07s/it]\n",
            "INFO:root:Running topp = 0.45\n",
            "100% 10/10 [01:00<00:00,  6.07s/it]\n",
            "INFO:root:Running topp = 0.5\n",
            "100% 10/10 [01:00<00:00,  6.07s/it]\n",
            "INFO:root:Running topp = 0.55\n",
            "100% 10/10 [01:00<00:00,  6.08s/it]\n",
            "INFO:root:Running topp = 0.6\n",
            "100% 10/10 [01:00<00:00,  6.06s/it]\n",
            "INFO:root:Running topp = 0.65\n",
            "100% 10/10 [01:00<00:00,  6.06s/it]\n",
            "INFO:root:Running topp = 0.7\n",
            "100% 10/10 [01:00<00:00,  6.07s/it]\n",
            "INFO:root:Running topp = 0.75\n",
            "100% 10/10 [01:00<00:00,  6.07s/it]\n",
            "INFO:root:Running topp = 0.8\n",
            "100% 10/10 [01:00<00:00,  6.06s/it]\n",
            "INFO:root:Running topp = 0.85\n",
            "100% 10/10 [01:00<00:00,  6.06s/it]\n",
            "INFO:root:Running topp = 0.9\n",
            "100% 10/10 [01:00<00:00,  6.07s/it]\n",
            "INFO:root:Running topp = 0.95\n",
            "100% 10/10 [01:00<00:00,  6.06s/it]\n",
            "INFO:root:Running topp = 1.0\n",
            "100% 10/10 [01:00<00:00,  6.06s/it]\n",
            "INFO:root:Running topk = 1\n",
            "100% 10/10 [01:00<00:00,  6.08s/it]\n",
            "INFO:root:Running topk = 2\n",
            "100% 10/10 [01:00<00:00,  6.08s/it]\n",
            "INFO:root:Running topk = 5\n",
            "100% 10/10 [01:01<00:00,  6.14s/it]\n",
            "INFO:root:Running topk = 10\n",
            "100% 10/10 [01:01<00:00,  6.12s/it]\n",
            "INFO:root:Running topk = 20\n",
            "100% 10/10 [01:01<00:00,  6.13s/it]\n",
            "INFO:root:Running topk = 50\n",
            "100% 10/10 [01:01<00:00,  6.14s/it]\n",
            "INFO:root:Running topk = 100\n",
            "100% 10/10 [01:01<00:00,  6.13s/it]\n",
            "INFO:root:Running topk = 200\n",
            "100% 10/10 [01:01<00:00,  6.13s/it]\n",
            "INFO:root:Running topk = 500\n",
            "100% 10/10 [01:01<00:00,  6.12s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of the attack!"
      ],
      "metadata": {
        "id": "-dSiZIoMutde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --folder \"https://drive.google.com/drive/folders/1G0bxoe7lNfpaEQKqBb3JW5M0db9GJ5BR\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-3EtNFofiGu",
        "outputId": "5965a9a0-f82d-4482-f6f5-3c6c91dfa906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder list\n",
            "Retrieving folder 1De1bdq1BOa7rFl13eG_-qHK0m-v_UvQ9 evaluator\n",
            "Processing file 1ISNjwa_QrloDfbTrxoHu_hCUbII0g90v config.json\n",
            "Processing file 1bCg6CPX9uxH6KeeIHDHtaATYIQTljDto pytorch_model.bin\n",
            "Retrieving folder 1saRrjn63eCSW8boc-4IfK8Q5NZYubijz scorer\n",
            "Processing file 1_ennUtYbxewxb8Y5vjI7d5Z5y9mooTIX config.json\n",
            "Processing file 10UmcuYU4H82g9nvYRBqTo_avnwnJyEOI pytorch_model.bin\n",
            "Retrieving folder list completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ISNjwa_QrloDfbTrxoHu_hCUbII0g90v\n",
            "To: /content/Jailbreak_LLM/checkpoints/evaluator/config.json\n",
            "100% 764/764 [00:00<00:00, 3.82MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1bCg6CPX9uxH6KeeIHDHtaATYIQTljDto\n",
            "To: /content/Jailbreak_LLM/checkpoints/evaluator/pytorch_model.bin\n",
            "100% 433M/433M [00:02<00:00, 157MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_ennUtYbxewxb8Y5vjI7d5Z5y9mooTIX\n",
            "To: /content/Jailbreak_LLM/checkpoints/scorer/config.json\n",
            "100% 764/764 [00:00<00:00, 3.41MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10UmcuYU4H82g9nvYRBqTo_avnwnJyEOI\n",
            "To: /content/Jailbreak_LLM/checkpoints/scorer/pytorch_model.bin\n",
            "100% 433M/433M [00:02<00:00, 176MB/s]\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate.py \\\n",
        "    --model Llama-2-7b-chat-hf \\\n",
        "    --config 'greedy-only' \\\n",
        "    --evaluator_path  'checkpoints/evaluator'\\\n",
        "    --scorer_path 'checkpoints/scorer'"
      ],
      "metadata": {
        "id": "j5YUB5WUgvpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b58d3df-ebe3-4427-ca40-f7e76d03ebbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-29 04:01:00.414607: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 04:01:00.414682: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 04:01:00.414721: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 04:01:02.086211: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Llama-2-7b-chat-hf Llama-2-7b-chat-hf\n",
            "==== Greedy decoding ====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate.py \\\n",
        "    --model Llama-2-7b-chat-hf \\\n",
        "    --config 'exploited' \\\n",
        "    --evaluator_path  'checkpoints/evaluator'\\\n",
        "    --scorer_path 'checkpoints/scorer'"
      ],
      "metadata": {
        "id": "BwgGY_9bpaOC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a4dcfc0-75fe-4501-95b0-60fc427afed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-29 05:13:13.932268: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 05:13:13.932339: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 05:13:13.932382: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 05:13:15.972004: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Llama-2-7b-chat-hf Llama-2-7b-chat-hf\n",
            "==== Greedy decoding ====\n",
            "==== Exploiting temperature ====\n",
            " 45% 9/20 [00:02<00:02,  3.96it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 50% 10/20 [00:02<00:02,  3.92it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 55% 11/20 [00:02<00:02,  3.93it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 60% 12/20 [00:03<00:02,  3.98it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 65% 13/20 [00:03<00:01,  3.97it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 70% 14/20 [00:03<00:01,  3.95it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 75% 15/20 [00:03<00:01,  3.94it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 80% 16/20 [00:04<00:01,  3.72it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 85% 17/20 [00:04<00:00,  3.37it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 90% 18/20 [00:04<00:00,  3.19it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 95% 19/20 [00:05<00:00,  3.08it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "100% 20/20 [00:05<00:00,  3.64it/s]\n",
            "==== Exploiting Top_k ====\n",
            "  0% 0/9 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 11% 1/9 [00:00<00:02,  2.97it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 22% 2/9 [00:00<00:02,  2.87it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 33% 3/9 [00:01<00:02,  2.85it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 44% 4/9 [00:01<00:01,  2.92it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 56% 5/9 [00:01<00:01,  2.97it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 67% 6/9 [00:02<00:01,  2.93it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 78% 7/9 [00:02<00:00,  2.91it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 89% 8/9 [00:02<00:00,  3.19it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "100% 9/9 [00:02<00:00,  3.07it/s]\n",
            "==== Exploiting Top_p ====\n",
            "  0% 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "  5% 1/20 [00:00<00:04,  4.05it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 10% 2/20 [00:00<00:04,  4.06it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 15% 3/20 [00:00<00:04,  3.80it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 20% 4/20 [00:01<00:04,  3.90it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 25% 5/20 [00:01<00:03,  3.93it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 30% 6/20 [00:01<00:03,  4.02it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 35% 7/20 [00:01<00:03,  4.08it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 40% 8/20 [00:02<00:02,  4.04it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 45% 9/20 [00:02<00:02,  4.04it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 50% 10/20 [00:02<00:02,  4.07it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 55% 11/20 [00:02<00:02,  4.10it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 60% 12/20 [00:02<00:01,  4.04it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 65% 13/20 [00:03<00:01,  4.01it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 70% 14/20 [00:03<00:01,  4.04it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 75% 15/20 [00:03<00:01,  4.08it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 80% 16/20 [00:03<00:00,  4.03it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 85% 17/20 [00:04<00:00,  4.00it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 90% 18/20 [00:04<00:00,  4.08it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 95% 19/20 [00:04<00:00,  4.13it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "100% 20/20 [00:04<00:00,  4.05it/s]\n"
          ]
        }
      ]
    }
  ]
}