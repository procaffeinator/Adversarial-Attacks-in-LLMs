# Adversarial-Attacks-in-LLMs
Project for CS 6220
Group 21
Authors: Aheli Ghosh, Aviral Agrawal, Kriti Arora, Shrestha Mishra

Steps
1. Clone the repository.
2. Run each of the notebooks to replicate the results. Each notebook has instructions for changes required to run the attacks.

The results folder has results for each model with greedy and exhaustive decoding strategies.
